# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier  
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, auc
from sklearn.preprocessing import StandardScaler  # For scaling features
import joblib
import seaborn as sns
from sklearn.metrics import ConfusionMatrixDisplay, precision_recall_curve, average_precision_score

# Load datasets
train_df = pd.read_csv('/content/drive/MyDrive/DataSets/fraudTrain.csv')
test_df = pd.read_csv('/content/drive/MyDrive/DataSets/fraudTest.csv')

# Drop unnecessary columns
cols_to_drop = ['Unnamed: 0', 'cc_num', 'first', 'last', 'street', 'trans_num']
train_df = train_df.drop(columns=cols_to_drop)
test_df = test_df.drop(columns=cols_to_drop)

# Convert 'trans_date_trans_time' to datetime and extract features
for df in [train_df, test_df]:
    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])
    df['hour'] = df['trans_date_trans_time'].dt.hour
    df['day'] = df['trans_date_trans_time'].dt.day
    df['month'] = df['trans_date_trans_time'].dt.month
    df['year'] = df['trans_date_trans_time'].dt.year
    df.drop(columns=['trans_date_trans_time'], inplace=True)

# Convert 'dob' to age
for df in [train_df, test_df]:
    df['dob'] = pd.to_datetime(df['dob'], errors='coerce')  # Ensure valid datetime format
    df['age'] = df['dob'].apply(lambda x: 2024 - x.year if pd.notnull(x) else np.nan)
    df.drop(columns=['dob'], inplace=True)  # Drop original 'dob' column

# Handle 'gender' (binary categorical variable)
if 'gender' in train_df.columns:
    gender_mapping = {'M': 0, 'F': 1}
    train_df['gender'] = train_df['gender'].map(gender_mapping)
    test_df['gender'] = test_df['gender'].map(gender_mapping)

# One-hot encode 'city' and 'state'
categorical_columns = ['merchant', 'category', 'job', 'city', 'state']
for col in categorical_columns:
    combined_categories = pd.concat([train_df[col], test_df[col]]).drop_duplicates().reset_index(drop=True)
    category_mapping = {cat: idx for idx, cat in enumerate(combined_categories)}
    
    train_df[col] = train_df[col].map(category_mapping)
    test_df[col] = test_df[col].map(category_mapping)

# Fill missing values after mapping unseen categories
train_df.fillna(-1, inplace=True)
test_df.fillna(-1, inplace=True)

# Separate features and target variable
X_train = train_df.drop('is_fraud', axis=1)
y_train = train_df['is_fraud']
X_test = test_df.drop('is_fraud', axis=1)
y_test = test_df['is_fraud']

# Train-Test Split for validation
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)

# Scale features for MLP
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_val_scaled = scaler.transform(X_val)
X_test_scaled = scaler.transform(X_test)

# Initialize and train the MLP model
mlp_model = MLPClassifier(random_state=42, hidden_layer_sizes=(100,), max_iter=500)
mlp_model.fit(X_train_scaled, y_train)

# Make predictions
y_val_pred = mlp_model.predict(X_val_scaled)
y_test_pred = mlp_model.predict(X_test_scaled)

# Evaluate the model
print("Validation Classification Report:")
print(classification_report(y_val, y_val_pred))
print("Validation Confusion Matrix:")
print(confusion_matrix(y_val, y_val_pred))
print("Validation ROC-AUC Score:", roc_auc_score(y_val, mlp_model.predict_proba(X_val_scaled)[:, 1]))

print("\nTest Classification Report:")
print(classification_report(y_test, y_test_pred))
print("Test Confusion Matrix:")
print(confusion_matrix(y_test, y_test_pred))
print("Test ROC-AUC Score:", roc_auc_score(y_test, mlp_model.predict_proba(X_test_scaled)[:, 1]))

# Save the model (optional)
joblib.dump(mlp_model, 'fraud_detection_mlp_model.pkl')

# Confusion Matrix Visualization
conf_matrix_val = confusion_matrix(y_val, y_val_pred)
conf_matrix_test = confusion_matrix(y_test, y_test_pred)

fig, axes = plt.subplots(1, 2, figsize=(14, 6))

# For Validation set
disp_val = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_val, display_labels=['Not Fraud', 'Fraud'])
disp_val.plot(cmap='Blues', ax=axes[0])
axes[0].set_title('Validation Confusion Matrix')

# For Test set
disp_test = ConfusionMatrixDisplay(confusion_matrix=conf_matrix_test, display_labels=['Not Fraud', 'Fraud'])
disp_test.plot(cmap='Blues', ax=axes[1])
axes[1].set_title('Test Confusion Matrix')

plt.tight_layout()
plt.show()

# ROC Curve for validation and test sets
fpr_val, tpr_val, _ = roc_curve(y_val, mlp_model.predict_proba(X_val_scaled)[:, 1])
fpr_test, tpr_test, _ = roc_curve(y_test, mlp_model.predict_proba(X_test_scaled)[:, 1])

plt.figure(figsize=(10, 6))
plt.plot(fpr_val, tpr_val, label=f'Validation ROC Curve (AUC = {auc(fpr_val, tpr_val):.2f})')
plt.plot(fpr_test, tpr_test, label=f'Test ROC Curve (AUC = {auc(fpr_test, tpr_test):.2f})')
plt.plot([0, 1], [0, 1], 'k--')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend(loc='lower right')
plt.show()

# Precision-Recall Curve
precision_val, recall_val, _ = precision_recall_curve(y_val, mlp_model.predict_proba(X_val_scaled)[:, 1])
precision_test, recall_test, _ = precision_recall_curve(y_test, mlp_model.predict_proba(X_test_scaled)[:, 1])

plt.figure(figsize=(10, 6))
plt.plot(recall_val, precision_val, label=f'Validation Precision-Recall Curve (AP = {average_precision_score(y_val, mlp_model.predict_proba(X_val_scaled)[:, 1]):.2f})')
plt.plot(recall_test, precision_test, label=f'Test Precision-Recall Curve (AP = {average_precision_score(y_test, mlp_model.predict_proba(X_test_scaled)[:, 1]):.2f})')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend(loc='lower left')
plt.show()

# Feature importance visualization
# Although MLP does not directly provide feature importances, we can analyze the model weights (this part is optional)
# Feature importance visualization based on MLP's weights
# Display the weight coefficients for each feature (here we are assuming the first layer of MLP)
weights = mlp_model.coefs_[0]
plt.figure(figsize=(12, 8))
plt.barh(X_train.columns, np.abs(weights).mean(axis=1))  # Using mean absolute weights for each feature
plt.title('Feature Importance Based on MLP Weights')
plt.show()

# Heatmap for correlation matrix of the dataset
correlation_matrix = train_df.corr()
plt.figure(figsize=(12, 10))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')
plt.title('Correlation Matrix Heatmap')
plt.show()

# Pairplot to explore relationships between top 3 features
sns.pairplot(train_df[['age', 'hour', 'month', 'is_fraud']], hue='is_fraud', palette='coolwarm')
plt.suptitle("Pairplot for Features 'Age', 'Hour', 'Month' and 'is_fraud'", y=1.02)
plt.show()
