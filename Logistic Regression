# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve
from sklearn.metrics import accuracy_score, f1_score
from imblearn.over_sampling import SMOTE
from xgboost import XGBClassifier
import joblib

# Load datasets
train_df = pd.read_csv('/content/drive/MyDrive/Data Set/fraudTrain.csv')
test_df = pd.read_csv('/content/drive/MyDrive/Data Set/fraudTest.csv')

# Drop unnecessary columns
cols_to_drop = ['Unnamed: 0', 'cc_num', 'first', 'last', 'street', 'trans_num']
train_df = train_df.drop(columns=cols_to_drop)
test_df = test_df.drop(columns=cols_to_drop)

# Convert 'trans_date_trans_time' to datetime and extract features
for df in [train_df, test_df]:
    df['trans_date_trans_time'] = pd.to_datetime(df['trans_date_trans_time'])
    df['hour'] = df['trans_date_trans_time'].dt.hour
    df['day'] = df['trans_date_trans_time'].dt.day
    df['month'] = df['trans_date_trans_time'].dt.month
    df['year'] = df['trans_date_trans_time'].dt.year
    df.drop(columns=['trans_date_trans_time'], inplace=True)

# Convert 'dob' to age
for df in [train_df, test_df]:
    df['dob'] = pd.to_datetime(df['dob'], errors='coerce')
    df['age'] = df['dob'].apply(lambda x: 2024 - x.year if pd.notnull(x) else np.nan)
    df.drop(columns=['dob'], inplace=True)

# Handle 'gender' (binary categorical variable)
if 'gender' in train_df.columns:
    gender_mapping = {'M': 0, 'F': 1}
    train_df['gender'] = train_df['gender'].map(gender_mapping)
    test_df['gender'] = test_df['gender'].map(gender_mapping)

# One-hot encode 'city' and 'state'
categorical_columns = ['merchant', 'category', 'job', 'city', 'state']
for col in categorical_columns:
    combined_categories = pd.concat([train_df[col], test_df[col]]).drop_duplicates().reset_index(drop=True)
    category_mapping = {cat: idx for idx, cat in enumerate(combined_categories)}
    train_df[col] = train_df[col].map(category_mapping)
    test_df[col] = test_df[col].map(category_mapping)

# Fill missing values after mapping unseen categories
train_df.fillna(-1, inplace=True)
test_df.fillna(-1, inplace=True)

# Ensure there are no non-numeric columns before training
assert train_df.select_dtypes(include=['object']).empty, "Train set still contains non-numeric columns!"
assert test_df.select_dtypes(include=['object']).empty, "Test set still contains non-numeric columns!"

# Separate features and target variable
X_train = train_df.drop('is_fraud', axis=1)
y_train = train_df['is_fraud']
X_test = test_df.drop('is_fraud', axis=1)
y_test = test_df['is_fraud']

# Train-Test Split for validation
X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42, stratify=y_train)

# Handle class imbalance with SMOTE
smote = SMOTE(random_state=42, sampling_strategy=0.2)
X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)

# Initialize and train XGBoost Classifier (improved model)
model = XGBClassifier(scale_pos_weight=25, random_state=42, use_label_encoder=False, eval_metric='logloss')
model.fit(X_train_smote, y_train_smote)

# Make predictions
y_val_pred = model.predict(X_val)
y_val_proba = model.predict_proba(X_val)[:, 1]
y_test_pred = model.predict(X_test)
y_test_proba = model.predict_proba(X_test)[:, 1]

# Evaluate the model
print("Validation Classification Report:")
print(classification_report(y_val, y_val_pred))
print("Validation Confusion Matrix:")
print(confusion_matrix(y_val, y_val_pred))
print("Validation ROC-AUC Score:", roc_auc_score(y_val, y_val_proba))

print("\nTest Classification Report:")
print(classification_report(y_test, y_test_pred))
print("Test Confusion Matrix:")
print(confusion_matrix(y_test, y_test_pred))
print("Test ROC-AUC Score:", roc_auc_score(y_test, y_test_proba))
accuracy = accuracy_score(y_test, y_test_pred)
print(f"Accuracy: {accuracy:.2f}")

# Adjust Decision Threshold and Evaluate
thresholds = np.arange(0.1, 1.0, 0.1)
best_threshold = 0.5
best_f1 = 0
for threshold in thresholds:
    y_test_pred_adjusted = (y_test_proba >= threshold).astype(int)
    f1 = f1_score(y_test, y_test_pred_adjusted)
    if f1 > best_f1:
        best_f1 = f1
        best_threshold = threshold
print(f"Best Threshold: {best_threshold}, Best F1-Score: {best_f1:.2f}")

# Plot ROC Curve
fpr, tpr, _ = roc_curve(y_test, y_test_proba)
plt.figure(figsize=(10, 6))
plt.plot(fpr, tpr, label=f'XGBoost (AUC = {roc_auc_score(y_test, y_test_proba):.4f})')
plt.plot([0, 1], [0, 1], 'k--', label='Random Guess')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

# Plot Precision-Recall Curve
precision, recall, _ = precision_recall_curve(y_test, y_test_proba)
plt.figure(figsize=(10, 6))
plt.plot(recall, precision, label='Precision-Recall Curve')
plt.xlabel('Recall')
plt.ylabel('Precision')
plt.title('Precision-Recall Curve')
plt.legend()
plt.show()

# Save the model (optional)
joblib.dump(model, 'fraud_detection_model_xgb.pkl')
